{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sc\n",
    "from scipy import linalg, optimize, constants, interpolate, special, stats\n",
    "import math as ma\n",
    "from math import exp, pow, sqrt, log\n",
    "import seaborn as sns \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "import keras\n",
    "from keras.utils import plot_model, to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import SGD\n",
    "import sklearn as sl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten vorverarbeiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# csv einlesen\n",
    "Vein = pd.read_csv('datensatz/vein.csv')\n",
    "# dataframe draus machen\n",
    "df = pd.DataFrame(Vein)\n",
    "\n",
    "#inputs und targets generieren (Spalte 1 für die Targets, Spalte 2 bis Ende für die Inputs)\n",
    "inputs = df.iloc[1:, 2:].values\n",
    "targets = df.iloc[1:, 1].values\n",
    "\n",
    "# Endocder benötigen wir nicht, da bereits über all Zahlen vorhanden sind\n",
    "\n",
    "# Zunächst reshape, damit aus dem 1-D Array ein 2-D Array wird\n",
    "targets = targets.reshape(-1, 1)\n",
    "#Dann OneHotCodierer\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "targets = onehotencoder.fit_transform(targets).toarray()\n",
    "targets = targets[:, 0:]\n",
    "\n",
    "# Jetzt in test und trainings Daten splitten\n",
    "inputs_train, inputs_test, targets_train, targets_test = train_test_split(inputs, targets, test_size = 0.3)\n",
    "\n",
    "# Standard Scalerer drüber laufen lassen\n",
    "sc = StandardScaler()\n",
    "inputs_train = sc.fit_transform(inputs_train)\n",
    "inputs_test = sc.transform(inputs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Aus dem eindimensionalen Targets wurde 2-D Daten gemacht\n",
    "# has_DM2 oder !hasDM_2, binär codiert\n",
    "print(targets_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotfunktion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funktion für Plot Loss\n",
    "from IPython.display import clear_output\n",
    "class PlotLosses(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.plot(self.x, self.losses, label=\"loss\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "        \n",
    "plot_losses = PlotLosses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kontrolle der Daten "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Training Inputs: 14 [(14, 3160)]\n",
      "Anzahl der Training Targets: 14 [(14, 2)]\n",
      "Anzahl der Test Inputs: 6 [(6, 3160)]\n",
      "Anzahl der Test Targets: 6 [(6, 2)]\n"
     ]
    }
   ],
   "source": [
    "print('Anzahl der Training Inputs: ' + str(len(inputs_train)) + ' [' + str(inputs_train.shape) + ']')\n",
    "print('Anzahl der Training Targets: ' + str(len(targets_train)) + ' [' + str(targets_train.shape) + ']')\n",
    "\n",
    "print('Anzahl der Test Inputs: ' + str(len(inputs_test)) + ' [' + str(inputs_test.shape) + ']')\n",
    "print('Anzahl der Test Targets: ' + str(len(targets_test)) + ' [' + str(targets_test.shape) + ']')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. MLP Modell "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigentliches MLP Modell definieren: Input Dimensionen = 3160, Aktivierungsfunktion Relu/Sigmoid mit callback Funktion um Fehler beobachten zu können"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veinModel = Sequential()\n",
    "\n",
    "veinModel.add(Dense(14, activation='relu', input_dim=3160))\n",
    "veinModel.add(Dense(10, activation='relu'))\n",
    "veinModel.add(Dense(5, activation='relu'))\n",
    "veinModel.add(Dense(2, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "veinModel.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "veinHistory=veinModel.fit(inputs_train, targets_train,\n",
    "          epochs=5,\n",
    "          batch_size=14,\n",
    "          verbose=1,\n",
    "          validation_data=(inputs_test, targets_test),                  \n",
    "          callbacks=[plot_losses])\n",
    "\n",
    "nochUnbekannterWert, score = veinModel.evaluate(inputs_test, targets_test, batch_size=6)\n",
    "\n",
    "print('------------------------------')\n",
    "\n",
    "print(nochUnbekannterWert)\n",
    "print('Accuracy: %.2f' % (score*100))\n",
    "\n",
    "print('------------------------------')\n",
    "print(veinModel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
