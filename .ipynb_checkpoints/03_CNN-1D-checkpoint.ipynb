{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sc\n",
    "from scipy import linalg, optimize, constants, interpolate, special, stats\n",
    "import math as ma\n",
    "from math import exp, pow, sqrt, log\n",
    "import seaborn as sns \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "import keras\n",
    "import random\n",
    "from keras.utils import plot_model, to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import Conv1D, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import SGD\n",
    "import sklearn as sl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 1D Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten vorverarbeiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 20)\n",
      "Input Shape :  (20, 20, 1)\n",
      "Training data shape :  (14, 20, 1) (14,)\n",
      "Testing data shape :  (6, 20, 1) (6,)\n",
      "\n",
      "-----------------\n",
      "+--------+----------+---------+\n",
      "| target | !has_DM2 | has_DM2 |\n",
      "+--------+----------+---------+\n",
      "|  0.0   |   1.0    |   0.0   |\n",
      "|  1.0   |   0.0    |   1.0   |\n",
      "|  0.0   |   1.0    |   0.0   |\n",
      "|  0.0   |   1.0    |   0.0   |\n",
      "|  0.0   |   1.0    |   0.0   |\n",
      "|  1.0   |   0.0    |   1.0   |\n",
      "|  0.0   |   1.0    |   0.0   |\n",
      "|  1.0   |   0.0    |   1.0   |\n",
      "|  1.0   |   0.0    |   1.0   |\n",
      "|  0.0   |   1.0    |   0.0   |\n",
      "|  1.0   |   0.0    |   1.0   |\n",
      "|  1.0   |   0.0    |   1.0   |\n",
      "|  1.0   |   0.0    |   1.0   |\n",
      "|  0.0   |   1.0    |   0.0   |\n",
      "+--------+----------+---------+\n"
     ]
    }
   ],
   "source": [
    "# csv einlesen\n",
    "Vein = pd.read_csv('datensatz/vein.csv')\n",
    "# dataframe draus machen\n",
    "df = pd.DataFrame(Vein)\n",
    "\n",
    "#inputs und targets generieren (Spalte 1 für die Targets, Spalte 2 bis Ende für die Inputs)\n",
    "inputs = df.iloc[1:, 2:].values\n",
    "targets = df.iloc[1:, 1].values\n",
    "\n",
    "#PCA VERSION 1\n",
    "\n",
    "#Standardscaler über inputs laufen lassen \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(inputs)\n",
    "\n",
    "# Apply transform to Inputs\n",
    "scaled_inputs = scaler.transform(inputs)\n",
    "\n",
    "# Make an instance of the Model\n",
    "pca = PCA(20) # ODER: pca = PCA(n_components=20)\n",
    "\n",
    "pca.fit(scaled_inputs)\n",
    "\n",
    "inputs_pca = pca.transform(scaled_inputs)\n",
    "\n",
    "print(inputs_pca.shape)\n",
    "\n",
    "# ODER DOCH ALS Array?! -> inputs.shape[0],1,3160\n",
    "inputs = inputs_pca.reshape(inputs_pca.shape[0],20,1).astype( 'float32' )\n",
    "\n",
    "print('Input Shape : ' , inputs.shape)\n",
    "random.shuffle(inputs)\n",
    "inputs_train, inputs_test, targets_train, targets_test = train_test_split(inputs, targets, test_size = 0.3)\n",
    "\n",
    "\n",
    "#(Anzahl Datenpunkte, Höhe, Breite, Kanäle)  \n",
    "print('Training data shape : ', inputs_train.shape, targets_train.shape)\n",
    "print('Testing data shape : ', inputs_test.shape, targets_test.shape)\n",
    "\n",
    "\n",
    "print('\\n-----------------')\n",
    "#TARGETS\n",
    "targets_train_categorial = to_categorical(targets_train)\n",
    "targets_test_categorial = to_categorical(targets_test)\n",
    "\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"target\", \"!has_DM2\", \"has_DM2\"]\n",
    "\n",
    "i = 0\n",
    "for target in targets_train_categorial:\n",
    "    hasNotDM2, hasDM2 = target\n",
    "    x.add_row([targets_train[i],hasNotDM2, hasDM2])\n",
    "    i+=1\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotfunktion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funktion für Plot Loss\n",
    "from IPython.display import clear_output\n",
    "class PlotLosses(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.plot(self.x, self.losses, label=\"loss\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "        \n",
    "plot_losses = PlotLosses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CNN-Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer conv1d_2: expected ndim=3, found ndim=4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2abac24d2f8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m               \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0;31m#Padding: same=dim(in)=dim(out), valid=no Padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m               \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m        \u001b[0;31m#Aktivierungsfunktion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m               input_shape=inputs_train.shape))   #Dimension des Inputs\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m veinModel.add(Conv1D(32, \n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                     \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m                     \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer conv1d_2: expected ndim=3, found ndim=4"
     ]
    }
   ],
   "source": [
    "veinModel = Sequential()\n",
    "\n",
    "veinModel.add(Conv1D(64,                #Anzahl der Filter\n",
    "              kernel_size=2,        #Dimensionen des Fensters\n",
    "              strides=1,            #Größe der Schritte\n",
    "              padding='same',           #Padding: same=dim(in)=dim(out), valid=no Padding\n",
    "              activation='relu',        #Aktivierungsfunktion\n",
    "              input_shape=inputs_train[0].shape))   #Dimension des Inputs\n",
    "\n",
    "veinModel.add(Conv1D(32, \n",
    "              kernel_size=2, \n",
    "              strides=1,            #Größe der Schritte\n",
    "              padding='same',           #Padding: same=dim(in)=dim(out), valid=no Padding\n",
    "              activation='relu',        #Aktivierungsfunktion\n",
    "              input_shape=inputs_train[0].shape))\n",
    "\n",
    "veinModel.add(Conv1D(16, \n",
    "              kernel_size=2, \n",
    "              strides=1,            #Größe der Schritte\n",
    "              padding='same',           #Padding: same=dim(in)=dim(out), valid=no Padding\n",
    "              activation='relu',        #Aktivierungsfunktion\n",
    "              input_shape=inputs_train[0].shape))\n",
    "\n",
    "veinModel.add(Flatten())                       #Feature-Vektor erzeugen\n",
    "veinModel.add(Dense(2, activation='softmax')) #dicht verschaltete Schicht - lernt Klassifikation!\n",
    "\n",
    "#backpropagation \n",
    "#Stochastic gradient descent\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True) #Parameter beim SGD Lernrate, Momentum, ...\n",
    "\n",
    "veinModel.compile(\n",
    "    optimizer=sgd, \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "#train the model\n",
    "history_veinModel=veinModel.fit(inputs_train, targets_train_categorial, \n",
    "          epochs=10,\n",
    "          batch_size=14,\n",
    "          verbose=1,\n",
    "          validation_data=(inputs_test, targets_test_categorial),  \n",
    "          callbacks=[plot_losses])\n",
    "\n",
    "\n",
    "print(veinModel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction für das erste Bild der Testmenge\n",
    "result_VeinModel=veinModel.predict(inputs_test_scaled[:])\n",
    "\n",
    "print ('Auswertung:')\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"!has_DM2\", \"has_DM2\", \"output\", \"target\", \"prediction\"]\n",
    "\n",
    "i = 0\n",
    "for predict in result_VeinModel:\n",
    "    hasNotDM2, hasDM2 = predict\n",
    "    output = np.argmax(predict)\n",
    "    target = np.argmax(targets_test_categorial[i])\n",
    "    check = '\\u2716'\n",
    "    if target == output:\n",
    "        check = u'\\u2714'\n",
    "    \n",
    "    x.add_row([hasNotDM2, hasDM2, output, target, check])\n",
    "    i+=1\n",
    "print(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
