{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sc\n",
    "from scipy import linalg, optimize, constants, interpolate, special, stats\n",
    "import math as ma\n",
    "from math import exp, pow, sqrt, log\n",
    "import seaborn as sns \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "import keras\n",
    "import random\n",
    "from keras.utils import plot_model, to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import Conv1D, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import SGD\n",
    "import sklearn as sl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 1D Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten vorverarbeiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape :  (20, 3160, 1)\n",
      "Training data shape :  (14, 3160, 1) (14,)\n",
      "Testing data shape :  (6, 3160, 1) (6,)\n",
      "\n",
      "Vor der Skalierung der Inputs:\n",
      "\n",
      "inputs_train max :  462.2309\n",
      "inputs_test max :  353.9975\n",
      "\n",
      "Nach der Skalierung der Inputs:\n",
      "\n",
      "inputs_train max (skaliert):  1.0\n",
      "inputs_test max (skaliert):  1.0\n",
      "\n",
      "Ein Skalierter Input..\n",
      "\n",
      "[[0.635613]\n",
      " [0.635613]\n",
      " [0.635613]\n",
      " ...\n",
      " [0.      ]\n",
      " [0.      ]\n",
      " [0.      ]]\n",
      "\n",
      "-----------------\n",
      "+--------+----------+---------+\n",
      "| target | !has_DM2 | has_DM2 |\n",
      "+--------+----------+---------+\n",
      "|  1.0   |   0.0    |   1.0   |\n",
      "|  1.0   |   0.0    |   1.0   |\n",
      "|  1.0   |   0.0    |   1.0   |\n",
      "|  0.0   |   1.0    |   0.0   |\n",
      "|  0.0   |   1.0    |   0.0   |\n",
      "|  1.0   |   0.0    |   1.0   |\n",
      "|  0.0   |   1.0    |   0.0   |\n",
      "|  1.0   |   0.0    |   1.0   |\n",
      "|  0.0   |   1.0    |   0.0   |\n",
      "|  0.0   |   1.0    |   0.0   |\n",
      "|  0.0   |   1.0    |   0.0   |\n",
      "|  1.0   |   0.0    |   1.0   |\n",
      "|  0.0   |   1.0    |   0.0   |\n",
      "|  1.0   |   0.0    |   1.0   |\n",
      "+--------+----------+---------+\n"
     ]
    }
   ],
   "source": [
    "# csv einlesen\n",
    "Vein = pd.read_csv('datensatz/vein.csv')\n",
    "# dataframe draus machen\n",
    "df = pd.DataFrame(Vein)\n",
    "\n",
    "#inputs und targets generieren (Spalte 1 für die Targets, Spalte 2 bis Ende für die Inputs)\n",
    "inputs = df.iloc[1:, 2:].values\n",
    "targets = df.iloc[1:, 1].values\n",
    "\n",
    "\n",
    "# ODER DOCH ALS Array?! -> inputs.shape[0],1,3160\n",
    "inputs = inputs.reshape(inputs.shape[0],3160,1).astype( 'float32' )\n",
    "print('Input Shape : ' , inputs.shape)\n",
    "random.shuffle(inputs)\n",
    "inputs_train, inputs_test, targets_train, targets_test = train_test_split(inputs, targets, test_size = 0.3)\n",
    "\n",
    "\n",
    "#(Anzahl Datenpunkte, Höhe, Breite, Kanäle)  \n",
    "print('Training data shape : ', inputs_train.shape, targets_train.shape)\n",
    "print('Testing data shape : ', inputs_test.shape, targets_test.shape)\n",
    "\n",
    "\n",
    "# INPUTS\n",
    "inputs_train_max = inputs_train[0].max()\n",
    "inputs_test_max = inputs_test[0].max()\n",
    "\n",
    "print('\\nVor der Skalierung der Inputs:\\n')\n",
    "print('inputs_train max : ', inputs_train_max)\n",
    "print('inputs_test max : ', inputs_test_max)\n",
    "\n",
    "\n",
    "inputs_train_scaled = inputs_train/inputs_train_max\n",
    "inputs_test_scaled = inputs_test/inputs_test_max\n",
    "\n",
    "print('\\nNach der Skalierung der Inputs:\\n')\n",
    "print('inputs_train max (skaliert): ', inputs_train_scaled[0].max())\n",
    "print('inputs_test max (skaliert): ', inputs_test_scaled[0].max())\n",
    "\n",
    "\n",
    "print('\\nEin Skalierter Input..\\n')\n",
    "print(inputs_train_scaled[0])\n",
    "\n",
    "\n",
    "print('\\n-----------------')\n",
    "#TARGETS\n",
    "targets_train_categorial = to_categorical(targets_train)\n",
    "targets_test_categorial = to_categorical(targets_test)\n",
    "\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"target\", \"!has_DM2\", \"has_DM2\"]\n",
    "\n",
    "i = 0\n",
    "for target in targets_train_categorial:\n",
    "    hasNotDM2, hasDM2 = target\n",
    "    x.add_row([targets_train[i],hasNotDM2, hasDM2])\n",
    "    i+=1\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotfunktion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funktion für Plot Loss\n",
    "from IPython.display import clear_output\n",
    "class PlotLosses(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.plot(self.x, self.losses, label=\"loss\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "        \n",
    "plot_losses = PlotLosses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CNN-Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14 samples, validate on 6 samples\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "veinModel = Sequential()\n",
    "\n",
    "veinModel.add(Conv1D(3000,                #Anzahl der Filter\n",
    "              kernel_size=30,        #Dimensionen des Fensters\n",
    "              strides=1,            #Größe der Schritte\n",
    "              padding='same',           #Padding: same=dim(in)=dim(out), valid=no Padding\n",
    "              activation='relu',        #Aktivierungsfunktion\n",
    "              input_shape=inputs_train_scaled[0].shape))   #Dimension des Inputs\n",
    "\n",
    "veinModel.add(Conv1D(2000, \n",
    "              kernel_size=30, \n",
    "              strides=1,            #Größe der Schritte\n",
    "              padding='same',           #Padding: same=dim(in)=dim(out), valid=no Padding\n",
    "              activation='relu',        #Aktivierungsfunktion\n",
    "              input_shape=inputs_train_scaled[0].shape))\n",
    "\n",
    "veinModel.add(Conv1D(1000, \n",
    "              kernel_size=30, \n",
    "              strides=1,            #Größe der Schritte\n",
    "              padding='same',           #Padding: same=dim(in)=dim(out), valid=no Padding\n",
    "              activation='relu',        #Aktivierungsfunktion\n",
    "              input_shape=inputs_train_scaled[0].shape))\n",
    "\n",
    "veinModel.add(Flatten())                       #Feature-Vektor erzeugen\n",
    "veinModel.add(Dense(2, activation='softmax')) #dicht verschaltete Schicht - lernt Klassifikation!\n",
    "\n",
    "#backpropagation \n",
    "#Stochastic gradient descent\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True) #Parameter beim SGD Lernrate, Momentum, ...\n",
    "\n",
    "veinModel.compile(\n",
    "    optimizer=sgd, \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "#train the model\n",
    "history_veinModel=veinModel.fit(inputs_train_scaled, targets_train_categorial, \n",
    "          epochs=5,\n",
    "          batch_size=14,\n",
    "          verbose=1,\n",
    "          validation_data=(inputs_test_scaled, targets_test_categorial),  \n",
    "          callbacks=[plot_losses])\n",
    "\n",
    "\n",
    "print(veinModel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction für das erste Bild der Testmenge\n",
    "result_VeinModel=veinModel.predict(inputs_test_scaled[:])\n",
    "\n",
    "print ('Auswertung:')\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"!has_DM2\", \"has_DM2\", \"output\", \"target\", \"prediction\"]\n",
    "\n",
    "i = 0\n",
    "for predict in result_VeinModel:\n",
    "    hasNotDM2, hasDM2 = predict\n",
    "    output = np.argmax(predict)\n",
    "    target = np.argmax(targets_test_categorial[i])\n",
    "    check = '\\u2716'\n",
    "    if target == output:\n",
    "        check = u'\\u2714'\n",
    "    \n",
    "    x.add_row([hasNotDM2, hasDM2, output, target, check])\n",
    "    i+=1\n",
    "print(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
